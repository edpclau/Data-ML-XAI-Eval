{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROAD Development Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.8               3.5                1.4               0.2   \n",
       "1                5.9               3.0                1.4               0.2   \n",
       "2                5.8               3.2                1.3               0.2   \n",
       "3                5.8               3.1                1.5               0.2   \n",
       "4                5.9               3.6                1.4               0.2   \n",
       "\n",
       "  species  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install numpy==1.23.1\n",
    "!pip install numba==0.56.4\n",
    "!pip install scikit-learn==1.0.2\n",
    "!pip install XGBoost==1.5.0 \n",
    "!pip install shap==0.39.0\n",
    "!pip install miceforest\n",
    "!pip install multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)\n",
      "sepal length (cm)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5,  2, 10])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Eddie Perez Claudio\n",
    "# The goal of this script is to evaluate the performance of XAI methods on the simulated datasets using the ROAD method.\n",
    "\n",
    "## Import Libraries ##\n",
    "\n",
    "#XAI\n",
    "import shap\n",
    "\n",
    "# Data wrangling\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "## Libraries ##\n",
    "#General\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "#Model Evalutation\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score, average_precision_score, recall_score\n",
    "import shap\n",
    "import shap.benchmark\n",
    "\n",
    "# multiprocessing\n",
    "from multiprocess.pool import Pool\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove and Retrain ####\n",
    "# This is a version of ROAD (as described in Rong et al 2022) \n",
    "# which works with any scikit-learn model and tabular data (pandas dataframes)\n",
    "#### Code ####\n",
    "\n",
    "## Explanation Function ##\n",
    "# Trains a model, builds an explanation with KernelShap, and then\n",
    "# outputs the ranking of each feature in descending order.\n",
    "# Arguments:\n",
    "# clf : A trained ML model with a .predict method\n",
    "# X: Training data as pandas dataframe\n",
    "# x:  Test data as pandas dataframe\n",
    "# explainer: any explainer that follows the shap api format \n",
    "def explain(clf, X, x, explainer = shap.explainers.Permutation):\n",
    "    if explainer != shap.explainers.Tree and explainer != shap.explainers.Linear:\n",
    "        try:\n",
    "                    # #Build Explanation\n",
    "            explanation = explainer(clf.predict_proba, X)\n",
    "            shap_values = np.abs(explanation(x).values[...,1]).mean(0)\n",
    "            return shap_values\n",
    "        \n",
    "        except:\n",
    "        # #Build Explanation\n",
    "            explanation = explainer(clf.predict, X)\n",
    "            shap_values = np.abs(explanation(x).values).mean(0)\n",
    "            return shap_values\n",
    "\n",
    "    elif explainer == shap.explainers.Tree:\n",
    "        # #Build Explanation\n",
    "        explanation = explainer(clf, X)\n",
    "        shap_values = explanation(x).values\n",
    "        if len(shap_values.shape) == 2:\n",
    "            shap_values = np.abs(shap_values).mean(0)\n",
    "        else:\n",
    "            shap_values = np.abs(shap_values[...,1]).mean(0)\n",
    "        return shap_values\n",
    "    else:\n",
    "        # #Build Explanation\n",
    "        explanation = explainer(clf, X)\n",
    "        shap_values = np.abs(explanation(x).values).mean(0)\n",
    "        return shap_values\n",
    "\n",
    "\n",
    "## Ranking Function ##\n",
    "# Outputs the ranking of each feature in descending order.\n",
    "# Arguments:\n",
    "# shap_values: the output of any shap explainer\n",
    "def ranker(shap_values):\n",
    "    values = copy.deepcopy(shap_values)     \n",
    "    #Get ranks\n",
    "    ranks = np.argsort(values)\n",
    "    return ranks\n",
    "\n",
    "\n",
    "## Metrics function ##\n",
    "# Utility function which outputs a series of metrics to evaluate\n",
    "# Currently gets accuracy, balanced_accuracy, and f-score\n",
    "\n",
    "#Arguments:\n",
    "#clf: A trained ML model with a predict method\n",
    "#x: a pd.DataFrame of test data\n",
    "#y: Target of the test data\n",
    "def metrics(clf, x, y):   \n",
    "    #Predict\n",
    "    # print(len(x))\n",
    "    yhat = clf.predict(x)\n",
    "    try:\n",
    "        yscore = clf.predict_proba(x)[:, 1]\n",
    "    except:\n",
    "        yscore = clf.decision_function(x)\n",
    "    #Get metrics\n",
    "    accu = accuracy_score(y, yhat)\n",
    "    accu_balanced = balanced_accuracy_score(y, yhat)\n",
    "    f1 = f1_score(y, yhat)\n",
    "    auroc = roc_auc_score(y, yscore)\n",
    "    auprc = average_precision_score(y, yscore)\n",
    "    recall = recall_score(y, yhat)\n",
    "        \n",
    "    return np.array([[accu], [accu_balanced], [f1], [auroc], [auprc], [recall]])\n",
    "\n",
    "\n",
    "\n",
    "## Imputation Function assistant ##\n",
    "\n",
    "def impute(i,k, rankings, x_test):\n",
    "       #Add NA values\n",
    "        x_test = mf.ampute_data(x_test, variables= x_test.columns[rankings[i:k]].to_list(), perc = 0.8, random_state=42)\n",
    "        #impute\n",
    "        variables = x_test.columns.to_list()\n",
    "        index = rankings.copy()[i:k].tolist().pop()\n",
    "        kds = mf.ImputationKernel(\n",
    "        x_test,\n",
    "        variable_schema={variables.pop(index) : variables},\n",
    "        save_all_iterations=True,\n",
    "        random_state=1991\n",
    "        )\n",
    "        # Run the MICE algorithm for 2 iterations\n",
    "        kds.mice(2)\n",
    "        # Return the completed dataset.\n",
    "        x_test = kds.complete_data()\n",
    "\n",
    "        return x_test\n",
    "\n",
    "\n",
    "## Mask Features ## \n",
    "#These functions mask data using imputation and retrain the ML model\n",
    "#They mask from the top %, bottom %, or random.\n",
    "\n",
    "# Arguments:\n",
    "# t: percentage or number of features to be masked in each iteration\n",
    "# rankings: a list of rankings (descending rankings) to guide the removal\n",
    "# X, x: dataframes of the data from which we will remove the features. Training set and testing set, respectively\n",
    "# Y, y: Targets for the training and testing sets, respectively\n",
    "#clf: Model to retrain\n",
    "# base: metrics of the full model. Used to compare the performance of the masked model\n",
    "# direction: direction of masking. Can be 'top', 'bottom', or 'random'\n",
    "# seed: seed for random number generator\n",
    "\n",
    "#Mask\n",
    "def mask(t, rankings, X, Y, x, y, clf, base = np.empty((3,1)), direction = 'top'):\n",
    "    #Make copies of our data to modify\n",
    "    X_train = copy.deepcopy(X)\n",
    "    x_test = copy.deepcopy(x)\n",
    "    results = copy.deepcopy(base)\n",
    "\n",
    "    ## Directional Masking ##\n",
    "    #Top\n",
    "    if direction == 'top':\n",
    "        #Set masking schedule and iterator\n",
    "        if type(t) != int:\n",
    "            j = int(np.round(len(rankings)*t))\n",
    "            i = len(rankings) - j\n",
    "            k = len(rankings)\n",
    "        else: \n",
    "            j = t\n",
    "            i = len(rankings) - t\n",
    "            k = len(rankings)\n",
    "\n",
    "        #Impute and Predict\n",
    "        while k >= j:\n",
    "            #Impute\n",
    "            x_test = impute(i,k, rankings, x_test)\n",
    "            #Predict\n",
    "            results =  np.hstack((results, metrics(clf, x_test, y)))\n",
    "            \n",
    "            #Move iterator forward\n",
    "            i -= j\n",
    "            k -= j\n",
    "\n",
    "        return results \n",
    "        \n",
    "    #Bottom\n",
    "    elif direction == 'bottom':   \n",
    "        #Set masking schedule\n",
    "        if type(t) != int:\n",
    "            j = int(np.round(len(rankings)*t))\n",
    "            i = 0\n",
    "            k = j\n",
    "        else:\n",
    "            j = t\n",
    "            i = 0\n",
    "            k = j\n",
    "\n",
    "        #Impute and Predict\n",
    "        while k <= len(rankings):\n",
    "            #Impute\n",
    "            x_test = impute(i,k, rankings, x_test)\n",
    "            #Predict\n",
    "            results =  np.hstack((results, metrics(clf, x_test, y)))\n",
    "            \n",
    "            #Move iterator forward\n",
    "            i += j\n",
    "            k += j\n",
    "        return results\n",
    "    \n",
    "    #Random\n",
    "    elif direction == 'random':\n",
    "        np.random.seed(42)\n",
    "        random_choices = np.random.permutation(rankings)\n",
    "        #Set masking schedule\n",
    "        if type(t) != int:\n",
    "            j = int(np.round(len(rankings)*t))\n",
    "            i = 0\n",
    "            k = j\n",
    "        else:\n",
    "            j = t\n",
    "            i = 0\n",
    "            k = j\n",
    "\n",
    "        #Impute and Predict\n",
    "        while k <= len(rankings):\n",
    "            #Impute\n",
    "            x_test = impute(i,k, random_choices, x_test)\n",
    "            #Predict\n",
    "            results =  np.hstack((results, metrics(clf, x_test, y)))\n",
    "            \n",
    "            #Move iterator forward\n",
    "            i += j\n",
    "            k += j\n",
    "        return results\n",
    "   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "## ROAD ##\n",
    "# The main function of the library.\n",
    "#Wraps all other functions in a nice pipeline which is easy to use.\n",
    "#Accepts any scikit-learn model. It was built and tested using a binary target.\n",
    "\n",
    "# Arguments:\n",
    "# model : the model to be re-trained\n",
    "# t: percentage of features to be removed in each iteration\n",
    "# X: Training data as pandas dataframe\n",
    "# Y: Target values for training (This was build using a binary target)\n",
    "# x:  Test data as pandas dataframe\n",
    "# y: Target values for testing\n",
    "# explainer: any explainer which built with the shap api\n",
    "# repeats: how many times to explain and do the whole retraining\n",
    "\n",
    "#outputs accuracy, balanced_accuracy, f1_score, and ranks for each iteration. \n",
    "def road(X, Y, x, y, model, explainer = None, t = 0.10, shap_values = None):\n",
    "    #Initialize variables\n",
    "    base = metrics(model, x, y)\n",
    "    if explainer != None:\n",
    "        values = explain(model, X, x, explainer)\n",
    "        ranks = ranker(values)\n",
    "       \n",
    "    elif shap_values != None:\n",
    "        values = shap_values\n",
    "        ranks = ranker(values)\n",
    "    else:\n",
    "        print('Must supply either an explainer or shap_values')\n",
    "        return\n",
    "    \n",
    "    top = mask(t, ranks, X, Y, x, y, model, base, direction='top')\n",
    "   \n",
    "    bottom = mask(t, ranks, X, Y, x, y, model, base, direction='bottom')\n",
    "  \n",
    "    random = mask(t, ranks, X, Y, x, y, model, base, direction='random')\n",
    "\n",
    "    \n",
    "\n",
    "    #Set progress bar\n",
    "    # Repeat x times\n",
    "    for i in range(repeats-1):\n",
    "                #Initialize\n",
    "        if explainer != None:\n",
    "            iter_values = explain(model, X, x, explainer)\n",
    "            ranks = ranker(iter_values)\n",
    "            values = np.dstack((values, iter_values))\n",
    "        elif shap_values != None:\n",
    "            ranks = ranker(values)\n",
    "        else:\n",
    "            print('Must supply either an explainer or shap_values')\n",
    "            return\n",
    "        top = np.dstack((top, mask(t, ranks, X, Y, x, y, model, base, direction='top')))\n",
    "        bottom = np.dstack((bottom, mask(t, ranks, X, Y, x, y, model, base, direction='bottom')))\n",
    "        random = np.dstack((random, mask(t, ranks, X, Y, x, y, model, base, direction='random')))\n",
    "    return [top, bottom, random, values]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faux Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a faux model for the data\n",
    "## This will only work for ShapSampling and ShapKernel, or ShapPermutation\n",
    "\n",
    "class faux_model:\n",
    "  def __init__(self):\n",
    "      self.name = 'FauxModel'\n",
    "\n",
    "  @staticmethod\n",
    "  def predict(x):\n",
    "    if str(type(x)).__contains__('pandas'):\n",
    "      x = x.to_numpy()\n",
    "    \n",
    "    return x[:,0:3].prod(axis = 1)\n",
    "  \n",
    "  def predict_proba(self, x):\n",
    "    yhat = self.predict(x)\n",
    "    return np.array([np.where(yhat == 0, 1, 0),yhat]).T\n",
    "\n",
    "\n",
    "# y = data['3_vars_corr_2HC_n10000.csv']['y_test']\n",
    "# x = data['3_vars_corr_2HC_n10000.csv']['X_test']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Eval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_vars_corr_0HC_n25000.csv', '0_vars_corr_0HC_n100.csv', '0_vars_corr_0HC_n10000_skew_0.7354.csv', '3_vars_corr_1HC_n10000.csv', '0_vars_corr_0HC_n10000_skew_0.8612.csv', '0_vars_corr_0HC_n15000.csv', '2_vars_corr_1HC_n10000.csv', '0_vars_corr_0HC_n10000_skew_0.9694.csv', '2_vars_corr_2HC_n10000.csv', '0_vars_corr_0HC_n10000.csv', '0_vars_corr_0HC_n5000.csv', '0_vars_corr_0HC_n10000_skew_0.508.csv', '0_vars_corr_0HC_n10000_skew_0.6222.csv', '3_vars_corr_2HC_n10000B.csv', '0_vars_corr_0HC_n1000.csv', '0_vars_corr_0HC_n30000.csv', '3_vars_corr_2HC_n10000.csv', '0_vars_corr_0HC_n20000.csv']\n",
      "built\n"
     ]
    }
   ],
   "source": [
    "### Import Data ###\n",
    "# Simulated Datasets\n",
    "\n",
    "# Path to Simulated Datasets\n",
    "\n",
    "dir_path = '/Users/eddie/Library/CloudStorage/OneDrive-UniversityofPittsburgh/Research/XAI method performacne when Explainaing the PORT Dataset/Data/Simulated'\n",
    "\n",
    "# Lists to store files name\n",
    "res_ = []\n",
    "res = []\n",
    "for (dir_path, dir_names, file_names) in os.walk(dir_path):\n",
    "    res_.extend(file_names)\n",
    "for file in res_:\n",
    "    if file not in ['GroundTruth.csv', '.Rhistory', '.DS_Store']:\n",
    "        res.append(file)\n",
    "\n",
    "print(res)\n",
    "\n",
    "data = {}\n",
    "for file in res:\n",
    "    data_path = f'{dir_path}/{file}'\n",
    "    df = pd.read_csv(data_path)\n",
    "    train, test = train_test_split(df, test_size=0.25, random_state=42)\n",
    "    data[file] = {\n",
    "        'X_train': train.drop('Target', axis=1),\n",
    "        'y_train': train.Target,\n",
    "        'X_test': test.drop('Target', axis=1),\n",
    "        'y_test': test.Target\n",
    "    }\n",
    "\n",
    "\n",
    "### Import Models ###\n",
    "# Import Models\n",
    "# names = ['PassiveAgressive', 'SGDClassifier', 'RandomForest', 'Perceptron',\n",
    "#          'LogisticRegression', 'DecisionTree', 'XGBoost', 'GaussianNB']\n",
    "# file_models = {}\n",
    "# for file in res:\n",
    "#     models = {}\n",
    "#     for model in names:\n",
    "#         models[model] = joblib.load(\n",
    "#             f'/content/drive/MyDrive/XAI method performacne when Explainaing the PORT Dataset/Results/Models/Fitted Models/Simulated/{file}_{model}_optimized')\n",
    "#     file_models[file] = models\n",
    "\n",
    "### Model types ###\n",
    "# Linear Models\n",
    "linear = ['PassiveAgressive', 'SGDClassifier',\n",
    "          'Perceptron', 'RidgeClassifier', 'LogisticRegression']\n",
    "# Tree Models\n",
    "tree = ['RandomForest', 'DecisionTree', 'XGBoost']\n",
    "# Other\n",
    "other = ['MultinomialNB', 'GaussianNB', 'FauxModel']\n",
    "\n",
    "### Set Explainers ###\n",
    "# Explainers of Interest\n",
    "xai = {\n",
    "    'ShapLinear': shap.explainers.Linear,\n",
    "    'ShapTree': shap.explainers.Tree,\n",
    "    'ShapPermutation': shap.explainers.Permutation,\n",
    "    'ShapSampling': shap.explainers.Sampling\n",
    "}\n",
    "\n",
    "### Define Parallel Function ###\n",
    "def parallel_road(file, model_name, exp, rep):\n",
    "\n",
    "    #Check if exists\n",
    "    if os.path.isfile(f'/content/drive/MyDrive/XAI method performacne when Explainaing the PORT Dataset/Results/Evaluations/ROAD/SimTrack/Sampling Redo/{file}_{model_name}_{exp}_{rep}.joblib'):\n",
    "      return\n",
    "\n",
    "    df = data[file]\n",
    "    # models = file_models[file]\n",
    "    # model = models[model_name]\n",
    "    \n",
    "    #FauxModel\n",
    "    model = faux_model()\n",
    "    save_path = '/Users/eddie/Library/CloudStorage/OneDrive-UniversityofPittsburgh/Research/XAI method performacne when Explainaing the PORT Dataset/Results/Evaluations/ROAD/Big Sample Sizes'\n",
    "    #res_ = {}\n",
    "    # evaluate linear exps\n",
    "    if (model_name in linear) and (exp in ['ShapSampling', 'ShapLinear', 'ShapPermutation']):\n",
    "            res_ = road(df['X_train'], df['y_train'], df['X_test'],\n",
    "                                  df['y_test'], model=model, t=1,  explainer=xai[exp])\n",
    "            joblib.dump(res_, f'{save_path}/{file}_{model_name}_{exp}_{rep}.joblib', compress=3)\n",
    "\n",
    "    # eval tree exps\n",
    "    elif (model_name in tree) and (exp in ['ShapSampling', 'ShapTree', 'ShapPermutation']):\n",
    "            res_ = road(df['X_train'], df['y_train'], df['X_test'],\n",
    "                                  df['y_test'], model=model, t=1,  explainer=xai[exp])\n",
    "            joblib.dump(res_, f'{save_path}/{file}_{model_name}_{exp}_{rep}.joblib', compress=3)\n",
    "\n",
    "    # ev al agnostic exps\n",
    "    elif (exp in ['ShapSampling', 'ShapPermutation']):\n",
    "            res_ = road(df['X_train'], df['y_train'], df['X_test'],\n",
    "                                  df['y_test'], model=model, t=1,  explainer=xai[exp])\n",
    "            joblib.dump(res_, f'{save_path}/{file}_{model_name}_{exp}_{rep}.joblib', compress=3)\n",
    "    \n",
    "    else:\n",
    "      return\n",
    "\n",
    "    #joblib.dump(res_, f'/content/drive/MyDrive/XAI method performacne when Explainaing the PORT Dataset/Results/Evaluations/ROAD/SimOptim/{file}_{model_name}_optimized.joblib', compress=3)\n",
    "    return\n",
    "\n",
    "print('built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_vars_corr_0HC_n30000.csv', '0_vars_corr_0HC_n25000.csv', '0_vars_corr_0HC_n20000.csv']\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "ml = ['PassiveAgressive', 'SGDClassifier', 'RandomForest', 'Perceptron', 'LogisticRegression', 'DecisionTree', 'XGBoost', 'GaussianNB']\n",
    "exp = list(xai.keys())\n",
    "rep = list(range(5))\n",
    "\n",
    "\n",
    "large_samples = [res[-3], res[0], res[-1]]\n",
    "print(large_samples)\n",
    "print(len(exp)*len(large_samples)*len(rep))\n",
    "\n",
    "exp = ['ShapPermutation']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/eddie/Library/CloudStorage/OneDrive-UniversityofPittsburgh/Research/XAI method performacne when Explainaing the PORT Dataset/Code =)/ROAD_dev.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/eddie/Library/CloudStorage/OneDrive-UniversityofPittsburgh/Research/XAI%20method%20performacne%20when%20Explainaing%20the%20PORT%20Dataset/Code%20%3D%29/ROAD_dev.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39mdivide(\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.divide(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddie/miniconda3/envs/python_env/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n",
      "/Users/eddie/miniconda3/envs/python_env/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n",
      "/Users/eddie/miniconda3/envs/python_env/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n",
      "/Users/eddie/miniconda3/envs/python_env/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n",
      "Permutation explainer: 7501it [00:12, 124.34it/s]                          \n",
      "Permutation explainer: 7501it [00:12, 129.82it/s]                          \n",
      "Permutation explainer: 7501it [00:12, 131.06it/s]                          \n",
      "Permutation explainer: 7501it [00:12, 130.83it/s]                          \n",
      "Permutation explainer: 7501it [00:12, 132.70it/s]                          \n"
     ]
    }
   ],
   "source": [
    "## Paralelization ###\n",
    "if __name__ == '__main__':\n",
    "  pool = Pool(5)\n",
    "  results = pool.starmap_async(parallel_road, itertools.product(large_samples, ['FauxModel'], exp), chunksize=1)\n",
    "  results.get()\n",
    "   \n",
    "\n",
    "# for i in itertools.product(res, ml, exp):\n",
    "#   parallel_road(i[0], i[1], i[2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d4e42ab716de065dabed38619282a5a545b37a73470e3b37377cd94259c7c27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
